from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from diffusers import StableDiffusionPipeline
import torch

# Initialize FastAPI app
app = FastAPI()

# Load the Stable Diffusion model
model_path = "path_to_waifu_diffusion_or_stable_diffusion_model"
device = "cuda" if torch.cuda.is_available() else "cpu"
pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16).to(device)

# Request model
class ImageRequest(BaseModel):
    prompt: str
    negative_prompt: str = None
    num_inference_steps: int = 50
    guidance_scale: float = 7.5

@app.post("/generate")
def Image Generation(request: ImageRequest):
    try:
        # Generate the image
        image = pipe(
            prompt=request.prompt,
            negative_prompt=request.negative_prompt,
            num_inference_steps=request.num_inference_steps,
            guidance_scale=request.guidance_scale
        ).images[0]

        # Save the image to a file or return it as a response
        image_path = f"generated_images/{request.prompt.replace(' ', '_')}.png"
        image.save(image_path)
        return {"status": "success", "image_path": image_path}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))