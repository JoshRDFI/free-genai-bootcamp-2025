# Main docker compose file

services:
  ollama-server:
    image: ollama/ollama:latest
    container_name: ollama-server
    ports:
      - "8008:11434"
    volumes:
      - ../data/ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  llm_text:
    image: opea-docker-llm-text:latest
    container_name: llm_text
    ports:
      - "9000:9000"
    volumes:
      - ../data/ollama_data:/root/.ollama
      - ../data/shared_db:/app/db
    environment:
      - OLLAMA_HOST=ollama-server
      - LLM_SERVICE_PORT=9000
    depends_on:
      - ollama-server
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  guardrails:
    image: opea-docker-guardrails:latest
    container_name: guardrails
    ports:
      - "9400:9400"
    volumes:
      - ../data/ollama_data:/root/.ollama
      - ../data/shared_db:/app/db
    environment:
      - OLLAMA_HOST=ollama-server
      - GUARDRAILS_SERVICE_PORT=9400
    depends_on:
      - ollama-server
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  chromadb:
    image: opea-docker-chromadb:latest
    container_name: chromadb
    ports:
      - "8050:8050"
    volumes:
      - ../data/chroma_data:/app/chromadb
    environment:
      - CHROMA_SERVER_PORT=8050
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  tts:
    image: opea-docker-tts:latest
    container_name: tts
    ports:
      - "9200:9200"
    volumes:
      - ../data/tts_data:/app/data/tts_data
    environment:
      - TTS_HOME=/app/data/tts_data
      - TTS_DATA_PATH=/app/data/tts_data
      - TTS_MODEL=xtts_v2
      - TTS_SERVICE_PORT=9200
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  asr:
    image: opea-docker-asr:latest
    container_name: asr
    ports:
      - "9300:9300"
    volumes:
      - ../data/asr_data:/app/data/whisper
    environment:
      - ASR_SERVICE_PORT=9300
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  llm-vision:
    image: opea-docker-llm-vision:latest
    container_name: llm-vision
    ports:
      - "9100:9100"
    volumes:
      - ../data/mangaocr_models:/app/data/mangaocr_models
    environment:
      - MANGAOCR_MODEL_PATH=/app/data/mangaocr_models
      - VISION_SERVICE_PORT=9100
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  waifu-diffusion:
    image: opea-docker-waifu-diffusion:latest
    container_name: waifu-diffusion
    ports:
      - "9500:9500"
    volumes:
      - ../data/waifu:/app/data/waifu-diffusion
    environment:
      - WAIFU_DIFFUSION_PORT=9500
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  embeddings:
    image: opea-docker-embeddings:latest
    container_name: embeddings
    ports:
      - "6000:6000"
    volumes:
      - ../data/embeddings:/app/data/embeddings
      - ../data/shared_db:/app/db
    environment:
      - EMBEDDING_SERVICE_HOST_IP=0.0.0.0
      - EMBEDDING_SERVICE_PORT=6000
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  vocabulary_generator:
    build:
      context: ./comps/vocabulary_generator
      dockerfile: Dockerfile
    container_name: vocabulary_generator
    ports:
      - "9103:9103"
    volumes:
      - ../data/shared_db:/app/data/shared_db
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

networks:
  default:
    name: opea-docker_default
