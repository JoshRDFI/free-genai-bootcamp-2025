version: "3.8"

services:
  ollama-server:
    image: ollama/ollama
    container_name: ollama-server
    ports:
      - ${LLM_ENDPOINT_PORT:-8008}:11434
    environment:
      no_proxy: ${no_proxy}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      LLM_MODEL_ID: ${LLM_MODEL_ID}
      host_ip: ${host_ip}

  opea-service:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: opea-service
    ports:
      - "9000:9000"
    environment:
      HUGGINGFACEHUB_API_TOKEN: ${HUGGINGFACEHUB_API_TOKEN}
      LLM_ENDPOINT: http://ollama-server:11434
    depends_on:
      - ollama-server
    volumes:
      - .:/app

networks:
  default:
    driver: bridge