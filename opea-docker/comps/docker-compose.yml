version: '3.8'
services:
  ollama-server:
    image: ollama/ollama
    container_name: ollama-server
    ports:
      - "${LLM_ENDPOINT_PORT:-8008}:11434"
    volumes:
      - ./app/data/ollama_data:/root/.ollama
      - ./app/data/shared_db:/app/db
    environment:
      - no_proxy=${no_proxy}
      - http_proxy=${http_proxy}
      - https_proxy=${https_proxy}
      - LLM_MODEL_ID=${LLM_MODEL_ID}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped

  llm_text:
    build:
      context: ./opea-docker/comps/llm_text
      dockerfile: Dockerfile
    container_name: llm_text
    ports:
      - "9000:9000"
    environment:
      - LLM_ENDPOINT=${LLM_ENDPOINT}
    depends_on:
      - ollama-server
    volumes:
      - ./opea-docker/comps/llm_text:/app
      - ./app/data/shared_db:/app/db
      - ./app/data/llm_xtts:/home/llm/.xtts_data
    restart: unless-stopped

  embeddings:
    build:
      context: ./opea-docker/comps/embeddings
      dockerfile: Dockerfile
    container_name: embeddings
    ports:
      - "6000:6000"
    environment:
      - EMBEDDING_SERVICE_HOST_IP=0.0.0.0
      - EMBEDDING_SERVICE_PORT=6000
    volumes:
      - ./opea-docker/comps/embeddings:/app
      - ./app/data/shared_db:/app/db
    restart: unless-stopped

  llm-vision:
    build:
      context: ./opea-docker/comps/llm-vision
      dockerfile: Dockerfile
    container_name: llm-vision
    ports:
      - "9100:9100"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      # Add vision-specific environment variables here if needed
    volumes:
      - ./opea-docker/comps/llm-vision:/app
      - ./app/data/shared_db:/app/db
      - ./app/data/mangaocr_models:/app/mangaocr_models
    restart: unless-stopped

  tts:
    build:
      context: ./opea-docker/comps/tts
      dockerfile: Dockerfile
    container_name: tts
    ports:
      - "9200:9200"
    volumes:
      - ./opea-docker/comps/tts:/app
      - ./app/data/shared_db:/app/db
      - ./app/data/tts_data:/home/tts/.xtts_data
    restart: unless-stopped

  asr:
    build:
      context: ./opea-docker/comps/asr
      dockerfile: Dockerfile
    container_name: asr
    ports:
      - "9300:9300"
    volumes:
      - ./opea-docker/comps/asr:/app
      - ./app/data/shared_db:/app/db
      - ./app/data/asr_data:/home/asr/.xtts_data
    restart: unless-stopped

  chromadb:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: chromadb
    volumes:
      - ./app/data/chroma_data:/data
      - ./app/data/shared_db:/app/db
    ports:
      - "8050:8050"
    restart: unless-stopped

  guardrails:
    build:
      context: ./opea-docker/comps/guardrails
      dockerfile: Dockerfile
    container_name: guardrails
    ports:
      - "9400:9400"
    volumes:
      - ./opea-docker/comps/guardrails:/app
      - ./app/data/shared_db:/app/db
    restart: unless-stopped